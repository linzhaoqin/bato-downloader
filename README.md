# Universal Manga Downloader (v3.1)

![Version](https://img.shields.io/badge/version-3.1.0-purple)
![License](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)

An extensible, user-friendly command-line tool to download manga chapters from various websites and automatically convert them into a single PDF file.

This tool is built on a **modular parser engine**, making it adaptable to future website changes and expandable to support new sites.

---

## What's New

-   **Bato.si compatibility restored** – the `Bato_V3` parser now understands the latest Qwik-powered page format (it decodes the embedded base36 token map to recover image URLs), so tricky chapters such as [OMORI Official ch. 10](https://bato.si/title/160779-en-omori-official/3735107-ch_10) download again without manual work.
-   **Parser modules runnable as scripts** – every parser still loads dynamically inside the app, but you can now execute `python3 parsers/bato_v3_parser.py` directly while developing to debug its output.

---

## Key Features

-   ✅ **Modular Parser Engine**: Intelligently cycles through available parsers to find one that works for the given URL. Highly extensible for future websites.
-   ✅ **Auto-Managed Dependencies**: Automatically installs required libraries on first run if they are missing.
-   ✅ **Automatic PDF Bundling**: Instantly merges all downloaded images into a single, high-quality PDF (can be skipped).
-   ✅ **Smart Folder Organization**: Creates folders named after the manga title and chapter.
-   ✅ **Advanced Web Scraping**: Uses `cloudscraper` to bypass anti-bot protections like Cloudflare.
-   ✅ **Cross-Platform Support**: Works flawlessly on Windows, macOS, and Linux.

---

## Before You Start: The Only Prerequisite

The **only** thing you need is **Python 3**.

#### How to check if Python 3 is installed?

Open your "Terminal" or "Command Prompt" and type `python3 --version` (or `python --version`). If you see a version number, you're ready. If not, download it from the [official Python website](https://www.python.org/downloads/), ensuring you check **"Add Python to PATH"** during installation.

---

## How to Use: Quick Start in 3 Steps

#### Step 1: Download The Tool
1.  Go to the project's GitHub page.
2.  Click the green **`< > Code`** button -> **`Download ZIP`**.
3.  Unzip the downloaded file.

#### Step 2: Set Up the Environment (optional but recommended)
1.  Open a terminal in the project folder.
2.  (Optional) Create and activate a virtual environment:
    -   `python3 -m venv .venv`
    -   macOS/Linux: `source .venv/bin/activate`
    -   Windows: `.venv\Scripts\activate`
3.  Install dependencies: `pip install -r requirements.txt`

> Tip: If you skip this step, the script will install missing packages automatically the first time you run it.

#### Step 3: Run the Downloader
1.  Copy a manga **chapter** URL from a supported site (e.g., Bato.to, comick.fun).
2.  Execute:
    ```bash
    python3 manga_downloader.py "https://example.com/chapter"
    ```
3.  Images will be saved under `~/Downloads/<Title>_<Chapter>` (or the directory you specify with `--output-dir`), and a PDF bundle will be generated by default.

### Command-Line Options

```
usage: manga_downloader.py [-h] [-o OUTPUT_DIR] [--skip-pdf] [--quiet] url

Download a manga chapter and optionally bundle it into a PDF.

positional arguments:
  url                   Manga chapter URL to download.

options:
  -o, --output-dir      Directory to store downloads (default: ~/Downloads)
  --skip-pdf            Download images only, do not generate a PDF bundle.
  --quiet               Suppress informational output.
```

---

## For Developers: How to Add a New Parser

This tool's strength is its modularity. To support a new website, you don't need to touch the main application.

1.  **Create a new parser file** in the `/parsers` directory (e.g., `my_site_parser.py`).
2.  **Create a parser class** that inherits from `BaseParser`.
3.  **Implement the `can_parse` and `parse` methods**:
    -   `can_parse(soup, url)`: A quick check to see if your parser can handle the page (e.g., check for a unique HTML tag or URL pattern).
    -   `parse(soup, url)`: The core logic to extract the `title`, `chapter`, and a list of `image_urls`. It should return a dictionary with these keys.
4.  **Done!** The main script will automatically detect and use your new parser.

---

## Troubleshooting

-   **"No suitable parser found"**: This means the URL is from a website or a page layout that is not yet supported.
-   **Script exits immediately**: Run the command without `--quiet` to see the status messages, and double-check the URL.
-   **Download fails**: Check your internet connection and the URL. Some sites block automated access—wait and try again if you hit rate limits.

## License

This project is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-nc-sa/4.0/).

In short, you are free to:
-   **Share** — copy and redistribute the material in any medium or format.
-   **Adapt** — remix, transform, and build upon the material.

Under the following terms:
-   **Attribution** — You must give appropriate credit.
-   **NonCommercial** — You may not use the material for commercial purposes.
-   **ShareAlike** — If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.
